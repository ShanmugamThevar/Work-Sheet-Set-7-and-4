{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The value of correlation coefficient will always be:\n",
    "\n",
    "Ans. C) between -1 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Which of the following cannot be used for dimensionality reduction?\n",
    "\n",
    "Ans. D) Ridge Regularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Which of the following is not a kernel in Support Vector Machines?\n",
    "\n",
    "Ans. C) hyperplane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Amongst the following, which one is least suitable for a dataset having non-linear decision \n",
    "boundaries?\n",
    "\n",
    "Ans. A) Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. In a Linear Regression problem, ‘X’ is independent variable and ‘Y’ is dependent variable, where ‘X’ \n",
    "represents weight in pounds. If you convert the unit of ‘X’ to kilograms, then new coefficient of ‘X’ will \n",
    "be? \n",
    "\n",
    "Ans. C) old coefficient of ‘X’ ÷ 2.205"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. As we increase the number of estimators in ADABOOST Classifier, what happens to the accuracy of \n",
    "the model?\n",
    "\n",
    "Ans. B) increases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Which of the following is not an advantage of using random forest instead of decision trees?\n",
    "\n",
    "Ans. C) Random Forests are easy to interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Which of the following are correct about Principal Components?\n",
    "\n",
    "Ans. B) Principal Components are calculated using unsupervised learning techniques and C) Principal Components are linear combinations of Linear Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Which of the following are applications of clustering?\n",
    "\n",
    "Ans. A) Identifying developed, developing and under-developed countries on the basis of factors like GDP, \n",
    "poverty index, employment rate, population and living index and C) Identifying spam or ham emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Which of the following is(are) hyper parameters of a decision tree?\n",
    "\n",
    "Ans. A) max_depth, B) max_features, and D) min_samples_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. What are outliers? Explain the Inter Quartile Range (IQR) method for outlier detection.\n",
    "\n",
    "Ans.  An outlier is an observation that lies an abnormal distance from other values in a random sample \n",
    "from a population. In a sense, this definition leaves it up to the analyst to decide what will be \n",
    "considered abnormal.\n",
    "\n",
    "The interquartile range (IQR) is a measure of variability, based on dividing a data set into quartiles. The values that divide each part are called the first, second, and third quartiles; and they are denoted by Q1, Q2, and Q3, respectively. Q1 is the “middle” value in the first half of the rank-ordered data set. Q2 is the median value in the set. Q3 is the “middle” value in the second half of the rank-ordered data set. The formula for inter-quartile range is given below\n",
    "\n",
    "IQR=Q3−Q1 Where, IQR=Inter-quartile range Q1 = First quartile Q3 = Third quartile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. What is the primary difference between bagging and boosting algorithms?\n",
    "\n",
    "Ans. Bagging: Bagging is also known as bootstrap aggregating sits on top of the majority voting \n",
    "principle. The samples are bootstrapped each time when the model is trained. When the samples \n",
    "are chosen, they are used to train and validate the predictions. The samples are then replaced back \n",
    "into the training set. The samples are selected at random. This technique is known as bagging. To \n",
    "sum up, base classifiers such as decision trees are fitted on random subsets of the original training\n",
    "set. Subsequently, the individual predictions are aggregated (voting or averaging etc.). The final \n",
    "results are then used as predictions. It reduces the variance of a black box estimator. Due to this \n",
    "the chances of overfitting is ruled out.\n",
    "\n",
    "Boosting: The concept of Adaptive Boost revolves around correcting previous classifier mistakes. \n",
    "Each classifier gets trained on the sample set and learns to predict. The misclassification errors are \n",
    "then fed into the next classifier in the chain and are used to correct the mistakes until the final model \n",
    "predicts accurate results. When a weak-classifier misclassifies a training sample, the algorithm then \n",
    "uses these very samples to improve the performance of the ensemble.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. What is adjusted R2 in linear regression. How is it calculated?\n",
    "\n",
    "Ans. Adjusted R2 and R2 both represent that how well the model fits the data points. But adjusted R2 penalizes the model for using more features. In case we increase the number of features in training data the R2 will increase but adjusted R2 will only increase if the new feature adds value to our model. Due to this reason adjusted R2is considered as a better evaluation metric than R2. Adjusted R2 is always less than or equal to R2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. What is the difference between standardisation and normalisation?\n",
    "\n",
    "Ans. In Normalization a dataset is scaled in such a way that all the data points lie between 0 and 1. \n",
    "Normalization is often called min-max scaling. \n",
    "\n",
    "In Standardization a dataset is scaled in such a way that the mean of data points becomes \n",
    "0 and standard deviation is 1. The transformed data may be positive as well as negative in \n",
    "standardization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. What is cross-validation? Describe one advantage and one disadvantage of using cross-validation. \n",
    "\n",
    "Ans.  Cross validation is a technique to fit a model on data set. In cross validation the data set is divided into ‘k’ number of sets where ‘k-1’ sets are used for training and 1 set is used as validation set. And this is done for all the set one by one and the final score of model is taken as average score of all the ‘k’ number of fits. \n",
    "\n",
    "Advantage of using Cross validation is that, there is no need of separate validation data, cross validation reduces chances of overfitting and gives a more generic model. \n",
    "\n",
    "Cross validation has a disadvantage that it takes more time to fit the model over a large dataset and the model built is more complex than the basic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is central limit theorem and why is it important?\n",
    "\n",
    "Ans. The central limit theorem states that the sampling distribution of the mean approaches a normal distribution, as the sample size increases and, the sample mean and standard deviation will be closer in value to the population mean and standard deviation. The central limit theorem tells us that no matter what the distribution of the population is, the shape of the sampling distribution will approach normality as the sample size (N) increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What is sampling? How many sampling methods do you know?\n",
    "\n",
    "Ans. Sampling is the process of selecting a representative group from the population under study and the target population is the total group of individuals from which the sample might be drawn. A sample is the group of people who take part in the investigation. The people who take part are referred to as “participants”.\n",
    "\n",
    "There are two types of sampling methods:\n",
    "\n",
    "a) Probability sampling: It involves random selection, allowing you to make strong statistical inferences about the whole group.\n",
    "\n",
    "b) Non-probability sampling: It involves non-random selection based on convenience or other criteria, allowing you to easily collect data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What is the difference between type 1 and typeII error?\n",
    "\n",
    "Ans. In statistical hypothesis testing, \n",
    "\n",
    "a) Type 1 error is the error caused by rejecting a null hypothesis when it is true.\n",
    "Type II error is the error that occurs when the null hypothesis is accepted when it is not true.\n",
    "\n",
    "b) Type 1 error is denoted by α (alpha) known as an error, also called the level of significance of the test.\n",
    "The Type II error is denoted by β (beta) and is also termed as the beta error.\n",
    "\n",
    "c) Type 1 error occurs when the null hypothesis is rejected even when there is no relationship between the variables.\n",
    "Type II error occurs when the null hypothesis is acceptable considering that the relationship between the variables is because of chance or luck, and even when there is a relationship between the variables.\n",
    "\n",
    "d) As a result, type 1 error researcher might end up believing that the hypothesis works even when it doesn’t.\n",
    "Type II error researcher might end up believing that the hypothesis doesn’t work even when it should."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What do you understand by the term Normal distribution?\n",
    "\n",
    "Ans. Normal distribution is also known as the Gaussian distribution. It is a probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence than data far from the mean. In graph form, normal distribution will appear as a bell curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What is correlation and covariance in statistics?\n",
    "\n",
    "Ans. Covariance: Covariance is a measure of how much two random variables vary together. It involves the relationship between two variables or datasets. It lies between -infinity and +infinity.It depends on scale of variable. Covariance has dimensions.\n",
    "\n",
    "Correlation: Correlation is a statistical measure that indicates how strongly two variables are related. It involves the relationship between multiple variables. It lies between -1 and +1. It is independent on scale of variable. Correlation is dimensionless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Differentiate between univariate ,Biavariate,and multivariate analysis.\n",
    "\n",
    "Ans. Univariate analysis: Univariate data consists of only one variable. The analysis of univariate data is the simplest form of analysis since the information deals with only one quantity that changes. It doesn't deal with causes or relationship and the main purpose of analysis is to describe the data and find patterns that exist within it.\n",
    "\n",
    "Bivariate analysis: Bivariate data involves two different variables. The analysis of this type of data deals with causes and relationships and the analysis is done to find out the relationship among the two variables. \n",
    "\n",
    "Multivariate analysis: Multivariate data involves three or more variable and it is categorized under multivariate. It is similar to bivariate but contains more than one dependent variable. The ways to perform analysis on this data depends on the goals to be achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. What do you understand by sensitivity and how would you calculate it?\n",
    "\n",
    "Ans. A sensitivity analysis determines how different values of an independent variable affect a particular dependent variable under a given set of assumptions. In other words, sensitivity analyses study how various sources of uncertainty in a mathematical model contribute to the model's overall uncertainty.\n",
    "\n",
    "The sensitivity is calculated by dividing the percentage change in output by the percentage change in input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. What is hypothesis testing? What is H0 and H1? What is H0 and H1 for two-tail test?\n",
    "\n",
    "Ans. Hypothesis testing is an act in statistics whereby an analyst tests an assumption regarding a population parameter. The methodology employed by the analyst depends on the nature of the data used and the reason for the analysis.\n",
    "\n",
    "H0 is the null hypothesis and H1 is the alternate hypothesis.\n",
    "\n",
    "An alternate hypothesis is always written with a ≠ or < or > sign. Please refer the below table for more clarity. If the alternate hypothesis is written with a ≠ sign that means that we are going to perform a 2-tailed test because chances are it could be more than 100 or less than 100 which makes it 2-tailed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. What is quantitative data and qualitative data?\n",
    "\n",
    "Ans. Quantitative data: Quantitative data is concerned with discovering facts about social phenomena. It assumes a fixed and measurable reality. Quantitative data are collected through measuring things. Data are analysed through numerical comparisons and statistical inferences. \n",
    "\n",
    "Qualitative data: Qualitative data is concerned with understanding human behaviour from the informant's perspective. It assumes a dynamuc and negotiated reality. Qualitative data are collected through participant observation and interviews. Data are analyzed by themes from descriptions by informants. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. How to calculate range and interquartile range?\n",
    "\n",
    "Ans. The Range is the difference between the lowest and highest values. It is calculated as:\n",
    "    Range = Maximum Value–Minimum Value.\n",
    "\n",
    "The interquartile range (IQR) is a measure of variability, based on dividing a data set into quartiles. The values that divide each part are called the first, second, and third quartiles; and they are denoted by Q1, Q2, and Q3, respectively.\n",
    "Q1 is the “middle” value in the first half of the rank-ordered data set.\n",
    "Q2 is the median value in the set.\n",
    "Q3 is the “middle” value in the second half of the rank-ordered data set.\n",
    " The formula for inter-quartile range is given below\n",
    "\n",
    "IQR=Q3−Q1\n",
    "Where,\n",
    "IQR=Inter-quartile range\n",
    "Q1 = First quartile\n",
    "Q3 = Third quartile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. What do you understand by bell curve distribution ?\n",
    "\n",
    "Ans. The term \"bell curve\" is used to describe a graphical depiction of a normal probability distribution, whose underlying standard deviations from the mean create the curved bell shape. A standard deviation is a measurement used to quantify the variability of data dispersion, in a set of given values around the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Mention one method to find outliers.\n",
    "\n",
    "Ans. The most effective way to find all of the outliers is by using the interquartile range (IQR). The IQR contains the middle bulk of the data, so outliers can be easily found by knowing the IQR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. What is p-value in hypothesis testing?\n",
    "\n",
    "Ans. In statistics, the p-value is the probability of obtaining results at least as extreme as the observed results of a statistical hypothesis test, assuming that the null hypothesis is correct. The p-value is used as an alternative to rejection points to provide the smallest level of significance at which the null hypothesis would be rejected. A smaller p-value means that there is stronger evidence in favor of the alternative hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. What is the Binomial Probability Formula?\n",
    "\n",
    "Ans. Binomial probability refers to the probability of exactly x successes on n repeated trials in an experiment which has two possible outcomes. If the probability of success on an individual trial is p , then the binomial probability is nCx⋅px⋅(1−p)n−x. Here nCx indicates the number of different combinations of x objects selected from a set of n objects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Explain ANOVA and it’s applications.\n",
    "\n",
    "Ans. Analysis of variance, or ANOVA, is a statistical method that separates observed variance data into different components to use for additional tests. ANOVA is used for three or more groups of data, to gain information about the relationship between the dependent and independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a SQL query to show average number of orders shipped in a day (use Orders table).\n",
    "\n",
    "Ans. WITH x AS (SELECT 'shippedDate' COUNT('orderNumber') AS 'total_orders' FROM Orders) SELECT AVG('total_orders') AS 'AverageNumberOfOrdersShipped' FROM x;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a SQL query to show average number of orders placed in a day.\n",
    "\n",
    "Ans. WITH x AS (SELECT ‘orderDate’, COUNT(‘orderNumber’) AS ‘total_orders’ FROM Orders) \n",
    "\n",
    "SELECT AVG(‘total_orders’) AS ‘AverageNumberOfOrdersPlaced’ FROM x; \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a SQL query to show the product name with minimum MSRP (use Productstable).\n",
    "\n",
    "Ans. SELECT ‘productName’ FROM Products \n",
    "\n",
    "ORDER BY MSRP LIMIT 1; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write a SQL query to show the product name with maximum value ofstockQuantity.\n",
    "\n",
    "Ans. SELECT ‘productName’ FROM Products \n",
    "\n",
    "ORDER BY ‘quantityInStock’ DESC LIMIT 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Write a query to show the most ordered product Name (the product with maximum number of orders).\n",
    "\n",
    "Ans. SELECT ‘productName’ \n",
    "\n",
    "FROM OrderDetails AS a INNER JOIN Products AS b ON \n",
    "\n",
    "a.’productCode’ = b.’productCode’ \n",
    "\n",
    "GROUP BY b.’productCode’ \n",
    "\n",
    "ORDER BY COUNT(‘orderNumber’) DESC LIMIT 1; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Write a SQL query to show the highest paying customer Name.\n",
    "\n",
    "Ans. WITH x AS (SELECT customerName, SUM(amount) AS total_payment \n",
    "\n",
    "FROM Customers AS a INNER JOIN Payments b ON \n",
    "\n",
    "a.customerNumber = b.customerNumber \n",
    "\n",
    "GROUP BY customerName) \n",
    "\n",
    "SELECT customerName, total_payment FROM x \n",
    "\n",
    "WHERE total_payment = (SELECT MAX(total_payment) FROM x); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Write a SQL query to show cutomerNumber, customerName of all the customers who are from Melbourne city.\n",
    "\n",
    "Ans. SELECT ‘customerNumber’, ‘customerName’ FROM Customers \n",
    "\n",
    "WHERE ‘city’= \"Melbourne\"; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Write a SQL query to show name of all the customers whose name start with “N”.\n",
    "\n",
    "Ans. SELECT ‘customerName’ FROM Customers \n",
    "\n",
    "WHERE ‘customerName’ REGEXP ‘^N*’; \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Write a SQL query to show name of all the customers whose phone start with ‘7’ and are from city ‘LasVegas’.\n",
    "\n",
    "Ans. SELECT ‘customerName’ FROM Customers \n",
    "\n",
    "WHERE ‘phones’ REGEXP “^7.*” AND ‘city’ = “Las Vegas”; \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Write a SQL query to show name of all the customers whose creditLimit < 1000 and city is either “Las Vegas” or ”Nantes” or “Stavern”.\n",
    "\n",
    "Ans. SELECT ‘customerName’ FROM Customers \n",
    "\n",
    "WHERE ‘creditLimit’ < 1000 AND ‘city’ IN (\"Las Vegas\", \"Nantes\", \"Stavern\"); \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Write a SQL query to show all the orderNumber in which quantity ordered <10.\n",
    "\n",
    "Ans. SELECT ‘orderNumber’ FROM orderDetails \n",
    "\n",
    "WHERE ‘quantityOrdered’ < 10; \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Write a SQL query to show all the orderNumber whose customer Name start with letter ‘N’.\n",
    "\n",
    "Ans. SELECT ‘orderNumber’ \n",
    "\n",
    "FROM Customers AS a INNER JOIN orders AS b ON a.customerNumber = b.customerNumber WHERE ‘customerName’ REGEXP \"^B.*\"; \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Write a SQL query to show all the customerName whose orders are “Disputed” in status.\n",
    "\n",
    "Ans. SELECT ‘customerName’ \n",
    "\n",
    "FROM Orders AS a INNER JOIN Customers AS b ON \n",
    "\n",
    "a.’customerNumber’= b.’customerNumber’ WHERE ‘status’= \"Disputed\"; \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Write a SQL query to show the customerName who made payment through cheque with checkNumber startingwith H and made payment on “2004-10-19”. \n",
    "\n",
    "Ans. SELECT ‘customerName’ \n",
    "\n",
    "FROM Payments INNER JOIN Customers USING (‘customerNumber’) WHERE \n",
    "\n",
    "‘paymentDate’ = \"2004-10-19\" AND ‘checkNumber’ REGEXP \"^H.*\"; \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Write a SQL query to show all the checkNumber whose amount > 1000.\n",
    "\n",
    "Ans. SELECT ‘checkNumber’ FROM Payments \n",
    "\n",
    "WHERE ‘amount’ > 1000;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
